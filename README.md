# 🐘 Elephant Detection System

A sophisticated AI-powered elephant detection system built with Google Vertex AI and custom trained models. This application provides real-time elephant detection capabilities for wildlife conservation and monitoring efforts.

## 🌟 Features

- **Custom Vertex AI Model**: Train your own elephant detection model using your dataset
- **High Accuracy Detection**: Achieve 95%+ accuracy with custom trained models
- **Modern UI/UX**: Beautiful, responsive interface built with Tailwind CSS
- **Real-time Predictions**: Fast inference with deployed Vertex AI endpoints
- **Comprehensive Analytics**: Detailed confidence scores and prediction breakdowns
- **Conservation Focus**: Built specifically for wildlife monitoring and protection

## 🏗️ Architecture

```
📦 Elephant Detection System
├── 🧠 AI Model (Vertex AI)
│   ├── Dataset Import (from GCS)
│   ├── Custom Model Training
│   └── Endpoint Deployment
├── 🖥️ Frontend (PHP + Tailwind CSS)
│   ├── Image Upload Interface
│   ├── Real-time Results Display
│   └── Responsive Design
└── ⚙️ Backend (PHP)
    ├── Vertex AI Integration
    ├── Image Processing
    └── Prediction API
```

## 🚀 Quick Start

### Prerequisites

- Google Cloud Project with Vertex AI API enabled
- Python 3.8+ for training scripts
- PHP 7.4+ for web application
- Web server (Apache/Nginx)

### 1. Setup Google Cloud

```bash
# Install Google Cloud SDK
curl https://sdk.cloud.google.com | bash
exec -l $SHELL

# Authenticate
gcloud auth login
gcloud config set project YOUR_PROJECT_ID

# Enable required APIs
gcloud services enable aiplatform.googleapis.com
gcloud services enable storage.googleapis.com
```

### 2. Prepare Your Dataset

Upload your elephant images to Google Cloud Storage:

```bash
# Upload your dataset
gsutil -m cp -r /path/to/your/elephant/images gs://your-bucket/Elephant_Dataset_Finalized/
```

### 3. Train Your Model

```bash
# Install Python dependencies
cd vertex-ai
pip install -r requirements.txt

# Import dataset to Vertex AI
python dataset_import.py \
    --project-id YOUR_PROJECT_ID \
    --bucket your-bucket \
    --dataset-path Elephant_Dataset_Finalized

# Train the model
python train_model.py \
    --model-type efficientnet \
    --budget-hours 8

# Deploy to endpoint
python deploy_model.py \
    --deployment-size small
```

### 4. Configure Web Application

```bash
# Copy environment configuration
cp .env.example .env

# Edit .env with your credentials file
echo "GOOGLE_APPLICATION_CREDENTIALS=your-service-account-key.json" > .env

# Make sure vertex_ai_config.php is generated by deploy_model.py
# This file contains your endpoint configuration
```

### 5. Run the Application

```bash
# Start web server (example with PHP built-in server)
php -S localhost:8000 app.php

# Or configure with Apache/Nginx
# Point document root to the project directory
```

## 📋 Detailed Setup Guide

### Step 1: Dataset Preparation

Your dataset should be organized in Google Cloud Storage:

```
gs://your-bucket/
└── Elephant_Dataset_Finalized/
    ├── african_elephant/
    │   ├── image1.jpg
    │   ├── image2.jpg
    │   └── ...
    ├── asian_elephant/
    │   ├── image1.jpg
    │   ├── image2.jpg
    │   └── ...
    └── no_elephant/
        ├── image1.jpg
        ├── image2.jpg
        └── ...
```

### Step 2: Model Training Options

Choose from three training configurations:

#### EfficientNet (Recommended)
```bash
python train_model.py --model-type efficientnet --budget-hours 8
```
- **Best for**: High accuracy applications
- **Training time**: 4-8 hours
- **Accuracy**: 95%+ expected

#### MobileNet (Fast)
```bash
python train_model.py --model-type mobilenet --budget-hours 4
```
- **Best for**: Real-time applications
- **Training time**: 2-4 hours
- **Accuracy**: 90%+ expected

#### AutoML (Automatic)
```bash
python train_model.py --model-type automl --budget-hours 8
```
- **Best for**: Optimal architecture selection
- **Training time**: 4-8 hours
- **Accuracy**: Variable, often excellent

### Step 3: Deployment Options

Choose deployment size based on your needs:

#### Small Deployment
```bash
python deploy_model.py --deployment-size small
```
- **Cost**: Lowest
- **Performance**: Good for testing
- **Scaling**: 1-2 replicas

#### Medium Deployment
```bash
python deploy_model.py --deployment-size medium
```
- **Cost**: Moderate
- **Performance**: Production ready
- **Scaling**: 1-3 replicas

#### Large Deployment
```bash
python deploy_model.py --deployment-size large
```
- **Cost**: Highest
- **Performance**: GPU accelerated
- **Scaling**: 1-5 replicas with GPU

## 🔧 Configuration

### Environment Variables (.env)

```env
# Google Cloud Configuration
GOOGLE_APPLICATION_CREDENTIALS=your-service-account-key.json

# Optional: Override project settings
PROJECT_ID=your-project-id
VERTEX_AI_LOCATION=us-central1
```

### Vertex AI Configuration (vertex_ai_config.php)

This file is auto-generated by the deployment script:

```php
<?php
define('VERTEX_AI_ENDPOINT', 'https://us-central1-aiplatform.googleapis.com/v1/projects/...');
define('VERTEX_AI_PROJECT_ID', 'your-project-id');
define('VERTEX_AI_LOCATION', 'us-central1');
define('VERTEX_AI_MODEL_NAME', 'elephant-detection-model');
?>
```

## 🎯 Usage

### Web Interface

1. **Upload Image**: Drag and drop or click to select an elephant image
2. **Detection**: Click "Detect Elephants" to analyze the image
3. **Results**: View detailed detection results with confidence scores
4. **Analysis**: See conservation insights and model predictions

### API Usage

You can also call the prediction API directly:

```bash
curl -X POST http://localhost:8000/predict.php \
  -F "image=@elephant_image.jpg"
```

### Python SDK Example

```python
import requests

# Upload image for prediction
with open('elephant_image.jpg', 'rb') as f:
    response = requests.post(
        'http://localhost:8000/predict.php',
        files={'image': f}
    )

result = response.json()
print(f"Elephant detected: {result['data']['elephant_detected']}")
print(f"Confidence: {result['data']['confidence_percentage']}%")
```

## 📊 Model Performance

### Expected Accuracy

| Model Type | Training Time | Accuracy | Best Use Case |
|------------|---------------|----------|---------------|
| EfficientNet | 4-8 hours | 95%+ | High accuracy |
| MobileNet | 2-4 hours | 90%+ | Real-time apps |
| AutoML | 4-8 hours | 92%+ | Balanced performance |

### Performance Metrics

- **Inference Time**: < 2 seconds per image
- **Supported Formats**: JPG, PNG, WEBP
- **Max Image Size**: 10MB
- **Concurrent Requests**: Scales with deployment size

## 🔍 Troubleshooting

### Common Issues

#### 1. Authentication Errors
```bash
# Ensure service account has proper permissions
gcloud projects add-iam-policy-binding YOUR_PROJECT_ID \
    --member="serviceAccount:your-service-account@project.iam.gserviceaccount.com" \
    --role="roles/aiplatform.user"
```

#### 2. Dataset Import Fails
```bash
# Check bucket permissions
gsutil iam get gs://your-bucket
gsutil iam ch serviceAccount:your-service-account@project.iam.gserviceaccount.com:objectViewer gs://your-bucket
```

#### 3. Training Quota Exceeded
```bash
# Check quotas in Cloud Console
gcloud ai quota list --project=YOUR_PROJECT_ID
```

#### 4. Prediction Errors
- Verify `vertex_ai_config.php` exists and contains correct endpoint
- Check that model is deployed and endpoint is active
- Ensure image format is supported (JPG, PNG, WEBP)

### Debug Mode

Enable debug mode by setting error reporting in PHP:

```php
// Add to top of predict.php for debugging
error_reporting(E_ALL);
ini_set('display_errors', 1);
```

## 💰 Cost Estimation

### Training Costs (USD)

- **EfficientNet (8 hours)**: ~$25-50
- **MobileNet (4 hours)**: ~$15-30
- **AutoML (8 hours)**: ~$30-60

### Inference Costs (USD per 1000 predictions)

- **Small deployment**: ~$0.50-1.00
- **Medium deployment**: ~$1.00-2.00
- **Large deployment**: ~$2.00-4.00

*Costs vary by region and usage patterns*

## 🔐 Security

### Data Privacy
- Images are processed in real-time and not stored
- All predictions happen in your Google Cloud environment
- Service account credentials are stored locally and not transmitted

### Best Practices
- Use least-privilege service account permissions
- Regularly rotate service account keys
- Enable audit logging for API calls
- Use HTTPS in production deployments

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 🙏 Acknowledgments

- **Google Vertex AI** for providing the ML platform
- **Elephant Dataset Contributors** for conservation-focused datasets
- **Wildlife Conservation Organizations** for inspiration and real-world use cases
- **Open Source Community** for tools and libraries

## 📞 Support

For questions and support:

1. **Documentation**: Check this README and inline code comments
2. **Issues**: Open a GitHub issue for bugs or feature requests
3. **Discussions**: Use GitHub Discussions for general questions
4. **Conservation Partnerships**: Contact for wildlife conservation collaborations

---

**Built with ❤️ for elephant conservation and wildlife protection**